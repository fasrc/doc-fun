hpc_modules:
- name: python/3.12.8-fasrc01
  description: Python 3.12 with Anaconda distribution
  category: programming
- name: python/3.10.13-fasrc01
  description: Python 3.10 with Anaconda distribution
  category: programming
- name: R/4.4.3-fasrc01
  description: R statistical computing environment
  category: programming
- name: R/4.3.3-fasrc01
  description: R statistical computing environment
  category: programming
- name: julia/1.0.0-ncf
  description: Julia high-performance computing language
  category: programming
- name: matlab/R2024b-fasrc01
  description: MATLAB technical computing platform
  category: programming
- name: mathematica/13.3.0-fasrc01
  description: Mathematica computational software
  category: programming
- name: Anaconda2/2019.10-fasrc01
  description: Anaconda Python2 distribution
  category: programming
- name: Mambaforge/23.11.0-fasrc01
  description: Mamba Python implementation
  category: programming
- name: Miniforge3/24.11.3-fasrc02
  description: Miniforge Python implementation
  category: programming
- name: intelpython/3.9.16-fasrc01
  description: Intel distribution of Python
  category: programming
- name: gcc/14.2.0-fasrc01
  description: GNU Compiler Collection (latest)
  category: compiler
- name: gcc/13.2.0-fasrc01
  description: GNU Compiler Collection
  category: compiler
- name: gcc/12.2.0-fasrc01
  description: GNU Compiler Collection
  category: compiler
- name: intel/25.0.1-fasrc01
  description: Intel OneAPI compilers and tools (latest)
  category: compiler
- name: intel/24.2.1-fasrc01
  description: Intel OneAPI compilers and tools
  category: compiler
- name: nvhpc/24.11-fasrc01
  description: NVIDIA HPC SDK compilers
  category: compiler
- name: cuda/12.9.1-fasrc01
  description: NVIDIA CUDA toolkit (latest)
  category: gpu
- name: cuda/12.4.1-fasrc01
  description: NVIDIA CUDA toolkit
  category: gpu
- name: cuda/11.8.0-fasrc01
  description: NVIDIA CUDA toolkit (older stable)
  category: gpu
- name: cudnn/9.5.1.17_cuda12-fasrc01
  description: NVIDIA cuDNN deep learning library (latest)
  category: gpu
- name: cudnn/8.9.2.26_cuda12-fasrc01
  description: NVIDIA cuDNN deep learning library
  category: gpu
- name: openmpi/4.1.5-fasrc03
  description: Open MPI implementation (latest)
  category: parallel
- name: openmpi/4.1.4-fasrc01
  description: Open MPI implementation
  category: parallel
- name: mpich/4.3.0-fasrc01
  description: MPICH MPI implementation (latest)
  category: parallel
- name: mpich/4.2.2-fasrc01
  description: MPICH MPI implementation
  category: parallel
- name: intelmpi/2021.14-fasrc01
  description: Intel MPI library (latest)
  category: parallel
- name: intelmpi/2021.13-fasrc01
  description: Intel MPI library
  category: parallel
- name: fftw/3.3.10-fasrc01
  description: Fastest Fourier Transform in the West
  category: library
- name: hdf5/1.14.2-fasrc02
  description: HDF5 data model and file format (latest)
  category: library
- name: hdf5/1.12.2-fasrc01
  description: HDF5 data model and file format
  category: library
- name: netcdf-c/4.9.2-fasrc05
  description: NetCDF C libraries (latest)
  category: library
- name: netcdf-fortran/4.6.1-fasrc01
  description: NetCDF Fortran libraries
  category: library
- name: netcdf-cxx4/4.3.1-fasrc04
  description: NetCDF C++ libraries
  category: library
- name: gsl/2.8-fasrc01
  description: GNU Scientific Library
  category: library
- name: intel-mkl/25.0.1-fasrc01
  description: Intel Math Kernel Library (latest)
  category: library
- name: openblas/0.3.21-fasrc01
  description: Optimized BLAS library
  category: library
- name: cmake/3.31.6-fasrc01
  description: Cross platform build tool (latest)
  category: development
- name: cmake/3.30.3-fasrc01
  description: Cross platform build tool
  category: development
- name: autoconf/2.71-fasrc01
  description: GNU Autoconf build system
  category: development
- name: flex/2.6.4-fasrc01
  description: Lexical analyzer generator
  category: development
- name: jdk/23.0.2-fasrc01
  description: Java Development Kit (latest)
  category: development
- name: gaussian/16-fasrc04
  description: Gaussian computational chemistry software
  category: chemistry
- name: QChem/6.1-fasrc01
  description: Q-Chem quantum chemistry package
  category: chemistry
- name: comsol/6.3-fasrc01
  description: COMSOL Multiphysics simulation
  category: physics
- name: abaqus/2023-fasrc01
  description: Abaqus finite element analysis
  category: physics
- name: lumerical-seas/2024R1-fasrc01
  description: Lumerical FDTD simulation software
  category: physics
- name: rstudio/2024.12.1-fasrc01
  description: RStudio IDE for R (latest)
  category: datascience
- name: vscode/1.98-fasrc01
  description: Visual Studio Code editor (latest)
  category: datascience
- name: pycharm-community/2023.1-fasrc01
  description: PyCharm Python IDE
  category: datascience
- name: knime/5.4.4-fasrc01
  description: KNIME data analytics platform
  category: datascience
- name: sage/10.3-fasrc01
  description: SageMath mathematical software
  category: datascience
- name: gurobi/12.0.1-fasrc01
  description: Gurobi optimization solver
  category: optimization
- name: knitro/13.2.0-fasrc01
  description: KNITRO nonlinear optimization solver
  category: optimization
- name: magma/2.28.7-fasrc02
  description: Magma computational algebra system
  category: mathematics
- name: pari/2.15.5-fasrc01
  description: PARI/GP number theory system
  category: mathematics
cluster_commands:
- name: sbatch
  description: Submit batch job to SLURM scheduler
  usage: sbatch script.sh
  example: sbatch --partition=gpu --gres=gpu:1 my_job.sh
- name: squeue
  description: View job queue status
  usage: squeue -u username
  example: squeue -u $USER --format="%.18i %.9P %.30j %.8u %.8T %.10M %.9l %.6D %R"
- name: scancel
  description: Cancel submitted jobs
  usage: scancel job_id
  example: scancel 12345
- name: sinfo
  description: View cluster partition information
  usage: sinfo
  example: sinfo -p gpu --format="%20P %5a %10l %6t %6c %8z %7m %8d %19N"
- name: salloc
  description: Allocate interactive session
  usage: salloc --partition=shared --time=2:00:00
  example: salloc --partition=gpu --gres=gpu:1 --time=4:00:00 --mem=16G
- name: srun
  description: Run commands on allocated nodes
  usage: srun command
  example: srun --pty bash
- name: module
  description: Environment module system
  usage: module load/unload/list/avail/spider
  example: module load python/3.12.8-fasrc01 cuda/12.9.1-fasrc01
filesystems:
- name: /n/holyscratch01
  description: High-performance scratch storage (30-day purge)
  type: scratch
  usage: Temporary files, large datasets
  quota: 100TB default
- name: /n/home_lab
  description: Lab group home directories
  type: home
  usage: Source code, small datasets
  quota: 50GB default
- name: /n/holylabs
  description: Lab group shared storage
  type: shared
  usage: Persistent shared data
  quota: Varies by lab
- name: /n/holylfs
  description: Lustre high-performance filesystem
  type: performance
  usage: Large-scale parallel I/O
  quota: By allocation
partitions:
- name: shared
  description: Shared CPU nodes for general computing
  max_time: 30-00:00:00
  max_nodes: '1'
  cores_per_node: '48'
  memory_per_node: 192GB
- name: gpu
  description: GPU nodes with V100/A100 accelerators
  max_time: 7-00:00:00
  max_nodes: '4'
  gpu_types:
  - V100
  - A100
  memory_per_node: 384GB
- name: gpu_test
  description: GPU nodes for testing (shorter jobs)
  max_time: 00:30:00
  max_nodes: '1'
  gpu_types:
  - V100
  - A100
  memory_per_node: 384GB
- name: bigmem
  description: High-memory nodes for memory-intensive jobs
  max_time: 7-00:00:00
  max_nodes: '2'
  cores_per_node: '48'
  memory_per_node: 1TB
- name: serial_requeue
  description: Single-core jobs with preemption
  max_time: 30-00:00:00
  max_nodes: '1'
  preemptible: true
  cores_per_node: '1'
job_examples:
  basic_cpu:
    description: Basic CPU job submission
    script: '#!/bin/bash

      #SBATCH --job-name=my_job

      #SBATCH --partition=shared

      #SBATCH --time=4:00:00

      #SBATCH --ntasks=1

      #SBATCH --cpus-per-task=4

      #SBATCH --mem=16G

      #SBATCH --output=%j.out

      #SBATCH --error=%j.err


      module load python/3.12.8-fasrc01

      python my_script.py

      '
  gpu_job:
    description: GPU job with CUDA
    script: '#!/bin/bash

      #SBATCH --job-name=gpu_job

      #SBATCH --partition=gpu

      #SBATCH --gres=gpu:1

      #SBATCH --time=2:00:00

      #SBATCH --ntasks=1

      #SBATCH --cpus-per-task=8

      #SBATCH --mem=32G

      #SBATCH --output=%j.out

      #SBATCH --error=%j.err


      module load python/3.12.8-fasrc01 cuda/12.9.1-fasrc01

      python gpu_training.py

      '
  mpi_job:
    description: Multi-node MPI job
    script: '#!/bin/bash

      #SBATCH --job-name=mpi_job

      #SBATCH --partition=shared

      #SBATCH --nodes=2

      #SBATCH --ntasks-per-node=24

      #SBATCH --time=8:00:00

      #SBATCH --mem-per-cpu=4G

      #SBATCH --output=%j.out

      #SBATCH --error=%j.err


      module load gcc/14.2.0-fasrc01 openmpi/4.1.5-fasrc03

      mpirun ./my_mpi_program

      '
common_workflows:
  interactive_session:
    description: Start interactive computing session
    steps:
    - salloc --partition=shared --time=2:00:00 --mem=8G
    - module load python/3.12.8-fasrc01
    - python
  gpu_interactive:
    description: Interactive GPU session for development
    steps:
    - salloc --partition=gpu_test --gres=gpu:1 --time=30:00 --mem=16G
    - module load python/3.12.8-fasrc01 cuda/12.9.1-fasrc01
    - nvidia-smi
  file_transfer:
    description: Transfer files to/from cluster
    steps:
    - '# From local to cluster:'
    - scp file.txt username@login.rc.fas.harvard.edu:/n/home_user/
    - '# From cluster to local:'
    - scp username@login.rc.fas.harvard.edu:/path/to/file.txt .
best_practices:
- Always specify resource requirements accurately in SLURM scripts
- Use scratch storage (/n/holyscratch01) for temporary files and large datasets
- Load only necessary modules to avoid conflicts
- Test jobs interactively before submitting large batch jobs
- Monitor job progress with squeue and check resource usage
- Clean up scratch files regularly to maintain good cluster citizenship
- Use array jobs for parameter sweeps and multiple similar tasks
- Request appropriate walltime - too short kills jobs, too long delays scheduling
- Use module spider to find detailed information about specific modules
- Check module dependencies and conflicts before loading multiple modules
code_examples:
  markdown:
  - name: Readme
    file_path: src/User_Codes/Languages/Fortran/README.md
    language: markdown
    description: Code example
    file_hash: 21bdbcbec50a64025726d4c4df4574852aab6ea53e7f1575a868908763d81fed
    last_modified: 1753385871.9233458
    file_size: 1209
    directory: Fortran
    scanned_at: '2025-07-24T16:12:31.330807'
  - name: Readme
    file_path: src/User_Codes/Languages/Fortran/Example2/README.md
    language: markdown
    description: Code example
    file_hash: 3246f39a172767f1573bc77203f49a7bad068aa07360374d0bf93b4792f82747
    last_modified: 1753385871.9228692
    file_size: 718
    directory: Example2
    scanned_at: '2025-07-24T16:12:31.353953'
    slurm_files:
    - /Users/swinney/Projects/doc-fun/src/User_Codes/Languages/Fortran/Example2/run.sbatch
  - name: Readme
    file_path: src/User_Codes/Languages/Fortran/Example1/README.md
    language: markdown
    description: Code example
    file_hash: 6d48b89a02030b14b847e15324bcb71c99bbfec1e18cf431eda6ffbeb3e81dca
    last_modified: 1753385871.9223318
    file_size: 41072
    directory: Example1
    scanned_at: '2025-07-24T16:12:31.367204'
    slurm_files:
    - /Users/swinney/Projects/doc-fun/src/User_Codes/Languages/Fortran/Example1/run.sbatch
  fortran:
  - name: Sum
    file_path: src/User_Codes/Languages/Fortran/Example2/sum.f90
    language: fortran
    description: 'NAME:    sum.f90 PURPOSE: Computes sum of integers from 1 to 100'
    file_hash: e5ec23069d16256ade92d7afb2c607e8ee13e7c725f85210e3052b00a31e3783
    last_modified: 1753385871.9229915
    file_size: 531
    directory: Example2
    scanned_at: '2025-07-24T16:12:31.344300'
    slurm_files:
    - /Users/swinney/Projects/doc-fun/src/User_Codes/Languages/Fortran/Example2/run.sbatch
  - name: Lanczos
    file_path: src/User_Codes/Languages/Fortran/Example1/lanczos.f90
    language: fortran
    description: Standard Lanczos algorithm with re-orthogonalization Serial implementation
    file_hash: fd916365f078a07c55cc040a21ee173fb50922eff5e6a57f0d51c8f119176b2e
    last_modified: 1753385871.9224057
    file_size: 23691
    directory: Example1
    scanned_at: '2025-07-24T16:12:31.360685'
    slurm_files:
    - /Users/swinney/Projects/doc-fun/src/User_Codes/Languages/Fortran/Example1/run.sbatch
code_examples_metadata:
  last_scan: '2025-07-24T16:12:31.394183'
  total_examples: 5
  languages:
  - markdown
  - fortran
  scan_summary:
    markdown: 3
    fortran: 2
